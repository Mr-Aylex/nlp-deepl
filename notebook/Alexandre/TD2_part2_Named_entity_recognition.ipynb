{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7c0b40",
   "metadata": {},
   "source": [
    "# TD2 part 2: Named entity recognition\n",
    "\n",
    "Dans ce TD, nous allons prendre un datasets où les noms de personnes sont taggés.<br>\n",
    "Nous allons transformer ces données en tenseurs X, y et attention_mask.<br>\n",
    "Nous allons créer un modèle RNN pour prédire si un mot est un nom de personne.<br>\n",
    "Nous allons ensuite créer la loop avec l'optimizer pour apprendre le modèle.<br>\n",
    "Du modèle appris (prédisant sur les tokens), nous allons postprocess les prédictions pour avoir les prédictions sur les noms.\n",
    "\n",
    "Un fois que la loop est créée et que le modèle apprend, nous allons changer la structure du modèle:\n",
    "- Changer learning rate. Comment se comporte le modèle\n",
    "- Ajouter des couches denses, ReLU, dropout, normalization\n",
    "- Changer le nombre de layers du RNN, LSTM.\n",
    "\n",
    "Lorsqu'on a un bon modèle de prédiction pour les noms de personnes, nous allons l'appliquer à notre projet fil rouge.\n",
    "Utilisez-le tel que. Quelle accuracy ?\n",
    "Ré-entrainez la (les) dernière(s) couche(s) du modèle sur notre jeu de données. A-t-il gagné en accuracy ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86402ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:28:53.985144400Z",
     "start_time": "2023-11-09T14:28:52.544444200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f552fb",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Télécharger le dataset MultiNERD FR [ici](https://github.com/Babelscape/multinerd)<br>\n",
    "Mettez les données dans le dossier data/raw du projet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157bc913",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:28:53.991652200Z",
     "start_time": "2023-11-09T14:28:53.985144400Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_multinerd_person_words(filename=\"../data/raw/train_fr.tsv\"):\n",
    "    with open(filename) as f:\n",
    "        tagged_words = [line.strip().split(\"\\t\") for line in f]\n",
    "        \n",
    "        # Joining words until we meet a dot\n",
    "        # Word's label is 1 if 'PER' is in its tag\n",
    "        sentences = []\n",
    "        sentence_labels = []\n",
    "    \n",
    "        this_word = []\n",
    "        this_labels = []\n",
    "        for tagged_word in tagged_words:\n",
    "            if len(tagged_word) < 3:\n",
    "                # not a tagged word\n",
    "                continue\n",
    "            word = tagged_word[1]\n",
    "            tag = tagged_word[2]\n",
    "        \n",
    "            if word == '.':\n",
    "                sentences.append(\" \".join(this_word))\n",
    "                sentence_labels.append(this_labels)\n",
    "            \n",
    "                this_word = []\n",
    "                this_labels = []\n",
    "            else:\n",
    "                this_word.append(word)\n",
    "                this_labels.append(1 * tag.endswith(\"PER\"))\n",
    "\n",
    "    return sentences, sentence_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcba104b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:28:59.828300800Z",
     "start_time": "2023-11-09T14:28:53.991652200Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences, labels = extract_multinerd_person_words(\"../src/data/raw/td2/train_fr.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b09cc",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "En utilisant le tokenizer d'HuggingFace \"camembert-base\":\n",
    "- Transformer les phrases en tokens\n",
    "- Obtenez des vecteur y qui ont le même nombre d'entrées qu'il y a de tokens dans la phrase\n",
    "- Ayez un tenseur \"attention_mask\" pour savoir sur quels tokens on cherche à predire le label\n",
    "- Transformez les tokens en token_ids (avec le tokenizer)\n",
    "Avec tout cela, vous pouvez former vos tenseurs X, Y et attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8ff1ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:29:00.428642100Z",
     "start_time": "2023-11-09T14:28:59.828300800Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a3802c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:29:00.428642100Z",
     "start_time": "2023-11-09T14:29:00.428642100Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_tokens_and_labels_and_attention_mask(tokenizer, sentence, labels):\n",
    "    words = sentence.split()\n",
    "    tokens = []\n",
    "    tokens_label = []\n",
    "    attention_mask = []\n",
    "    \n",
    "    for word, label in zip(words, labels):\n",
    "        this_tokens = tokenizer.tokenize(word)\n",
    "        tokens += this_tokens\n",
    "        \n",
    "        this_labels = [0] * len(this_tokens)\n",
    "        this_labels[0] = label        \n",
    "        tokens_label += this_labels\n",
    "        \n",
    "        this_attention_mask = [1] + [0] * (len(this_tokens) - 1)\n",
    "        attention_mask += this_attention_mask\n",
    "        \n",
    "    return tokens, tokens_label, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066d1710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:29:00.428642100Z",
     "start_time": "2023-11-09T14:29:00.428642100Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens, label, padding_masks = build_tokens_and_labels_and_attention_mask(tokenizer, sentences[0], labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d73a2b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:29:00.449677400Z",
     "start_time": "2023-11-09T14:29:00.441164800Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_X_y_attention_mask(tokenizer, sentences, labels):\n",
    "    tokens = []\n",
    "    tokens_label = []\n",
    "    attention_mask = []\n",
    "    \n",
    "    for sentence, sentence_labels in tqdm(zip(sentences, labels), total=len(sentences)):\n",
    "        this_tokens, this_tokens_label, this_attention_mask = build_tokens_and_labels_and_attention_mask(tokenizer, sentence, sentence_labels)\n",
    "        tokens += this_tokens\n",
    "        tokens_label += this_tokens_label\n",
    "        attention_mask += this_attention_mask\n",
    "        \n",
    "    X = torch.tensor(tokenizer.convert_tokens_to_ids(tokens))\n",
    "    y = torch.tensor(tokens_label)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    \n",
    "    return X, y, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e62c9b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:30:03.664496500Z",
     "start_time": "2023-11-09T14:29:00.441164800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/140436 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d45cf69aecc948a7a1a54a98a6fe259d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y, attention_mask = build_X_y_attention_mask(tokenizer, sentences, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T14:30:03.664496500Z",
     "start_time": "2023-11-09T14:30:03.664496500Z"
    }
   },
   "id": "b8f05eceb28887d1"
  },
  {
   "cell_type": "markdown",
   "id": "feb94a39",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Contruisez un modèle RNN comme dans la partie 1. Pour l'instant, il prendra comme arguments:\n",
    "- Vocab size: le nombre de différents tokens du tokenizer (52 000 pour camembert-base)\n",
    "- Embedding dim: la dimension de l'embedding des tokens (par défaut 50)\n",
    "- hidden_dim: la dimension de l'état récurrent de votre RNN (par défaut 20)\n",
    "- tagset_size: la nombre de classes possibles pour les prédictions (ici 2)\n",
    "\n",
    "Dans le forward, votre modèle enchaînera les couches suivantes:\n",
    "- Un embedding\n",
    "- Un RNN\n",
    "- Un ReLU\n",
    "- Une couche linéaire\n",
    "- Un softmax pour que la somme des prédictions pour une entrée soit égale à 1 (la prédiction pour un élément et sa probabilité d'être dans chaque classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86e661ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:30:03.677071300Z",
     "start_time": "2023-11-09T14:30:03.664496500Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=64, tagset_size=2, RNN=torch.nn.LSTM):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = RNN(embedding_dim, hidden_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04004a",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "Je fournis ici une fonction prenant un modèle, des tenseurs X, y, attention_mask.\n",
    "Pour chaque batch:\n",
    "- La loop utilise le modèle pour prédire sur x_batch\n",
    "- Avec attention_mask, elle identifie sur quels tokens les prédictions compte\n",
    "- Elle regarde la cross entropy entre y\\[attention_ids\\] et yhat\\[attention_ids\\]\n",
    "- Elle output un dictionnaire avec le model et la loss au fur et à mesure des itérations\n",
    "\n",
    "Entraînez le modèle avec vos données. <br>\n",
    "Plottez la loss history.<br>\n",
    "Itérez sur le modèle pour l'améliorer:\n",
    "- Changer learning rate. Comment se comporte le modèle\n",
    "- Ajouter des couches denses, ReLU, dropout, normalization\n",
    "- Changer le nombre de layers du RNN, LSTM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b9833f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T14:30:03.686093300Z",
     "start_time": "2023-11-09T14:30:03.677071300Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, X, y, attention_masks, n_epochs=100, lr=0.05, batch_size=128):\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    loss_history = []\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X, y, attention_masks)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        iterator = tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, (x_batch, y_batch, mask) in iterator:\n",
    "            x_batch, y_batch, mask = x_batch.cuda(), y_batch.cuda(), mask.cuda()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            ids = mask.reshape(-1)\n",
    "            yhat = model(x_batch).reshape((-1, 2))[ids]\n",
    "            this_y = y_batch.reshape(-1)[ids]\n",
    "            \n",
    "            loss = loss_function(yhat, this_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            loss_history.append(loss.cpu().clone().detach())\n",
    "        \n",
    "            optimizer.step()\n",
    "            \n",
    "            s = np.round((np.mean(loss_history[-10:])), 2)\n",
    "            iterator.set_description(f\"Got loss at {epoch} {s}      \")\n",
    "    return {\"model\": model, \"loss_history\": loss_history}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model = RNN(len(tokenizer))\n",
    "model = model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T14:30:04.057041400Z",
     "start_time": "2023-11-09T14:30:03.677071300Z"
    }
   },
   "id": "5d1cdfd3dcc351e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/16227 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31b71c4633f544438d58ea7afe2e4060"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16227 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58322dd5f2194cf388b78e9a756422b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16227 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b076f3f4da374563a631c1c92d745b6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = train_model(model, X, y, attention_mask.cuda(), n_epochs=100, lr=0.001, batch_size=256)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-09T14:30:04.057041400Z"
    }
   },
   "id": "3ef7cc82119662bc"
  },
  {
   "cell_type": "markdown",
   "id": "f21a6933",
   "metadata": {},
   "source": [
    "## Postprocessing\n",
    "\n",
    "Créer une fonction prenant les prédictions du modèle (au niveau token) et sort les prédictions au niveau mot.<br>\n",
    "Par exemple, admettons que, pour un mot, la prédiction du 1er token est la seule qu'on considère.<br>\n",
    "si la phrase est \"Bonjour John\", avec les tokens \\[\"bon\", \"jour\", \"Jo\", \"hn\"\\] avec les predictions \\[0.12, 0.65, 0.88, 0.45\\]<br>\n",
    "Je veux récupérer les prédictions \"bonjour\": 0.12, \"John\": 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0316b3",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def postprocess_predictions(predictions, attention_mask):\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    attention_mask = attention_mask.cpu().detach().numpy()\n",
    "    \n",
    "    predictions = predictions[attention_mask == 1]\n",
    "    predictions = predictions[:, 1]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8562e3",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "predictions = postprocess_predictions(result[\"model\"](X.cuda()), attention_mask.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5a2954488ce6ac51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
